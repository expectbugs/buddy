# Super Memory System Upgrade Plan

## Root Cause Analysis

### Why Memory Search Failed
1. **Low Semantic Similarity Scores**: 
   - Query "What exactly did you say to me when I asked your name?" only achieved 0.345 similarity
   - Semantic embeddings struggle with temporal/sequential questions
   - System lacks episodic memory structure

2. **Missing Temporal Context**: 
   - Current system treats all memories as isolated facts
   - No temporal relationships between memories

3. **No Conversation Reconstruction**: 
   - Can't reconstruct past conversations from stored memories
   - No linking between related memories in a conversation

## Implementation Plan: Multi-Layer Memory System

### 1. Hybrid Search Implementation

#### Add BM25/BM42 Sparse Embeddings
- Implement Qdrant's native BM42 support for real-time IDF calculation
- Store both dense (semantic) and sparse (keyword) vectors
- Use Qdrant's Query API with prefetch for simultaneous searches

#### Custom Reranking Function
- Combine semantic scores, keyword matches, and temporal proximity
- Weight recent memories higher for "when" questions
- Boost exact phrase matches for quotes

### 2. Episodic Memory Layer

#### Conversation Episodes
- Store complete conversations as episode objects
- Link individual memories to their parent episodes
- Include conversation flow metadata (who said what when)

#### Temporal Indexing
- Add timestamp-based indexing for chronological retrieval
- Implement "temporal windows" for context-aware search
- Store relative timestamps within episodes

### 3. Multi-Resolution Memory Storage

Three levels of granularity:
1. **Atomic Memories**: Individual facts/statements (current system)
2. **Episode Memories**: Complete conversation turns with context
3. **Summary Memories**: High-level summaries with pointers to details

#### Bidirectional Linking
- Link summaries to their source episodes
- Link episodes to their atomic memories
- Enable drill-down from summary to exact quotes

### 4. Enhanced Memory Structure

```python
memory_structure = {
    "id": "uuid",
    "text": "content",
    "embedding": "dense_vector",
    "sparse_embedding": "bm42_vector",
    "timestamp": "absolute_time",
    "episode_id": "conversation_id",
    "episode_position": "turn_number",
    "speaker": "user/assistant",
    "parent_memory": "summary_id",
    "child_memories": ["atomic_ids"],
    "conversation_context": {
        "previous_turn": "id",
        "next_turn": "id",
        "topic_tags": ["names", "introduction"]
    }
}
```

### 5. Intelligent Query Processing

#### Query Intent Detection
- Classify queries: factual, temporal, conversational, quote-based
- Route to appropriate search strategy

#### Multi-Stage Retrieval
1. Broad semantic search for topic
2. Temporal filtering for time context
3. Keyword search for specific phrases
4. Episode reconstruction for conversations

### 6. Memory Reconstruction Pipeline

For "What did you say" queries:
1. Find relevant episode by topic/time
2. Retrieve all memories from that episode
3. Reconstruct conversation flow
4. Extract specific assistant responses
5. Return with full context

### 7. Implementation Phases

#### Phase 1: Hybrid Search
- Add FastEmbedSparse with BM42 model
- Modify storage to include sparse embeddings
- Update search to use RetrievalMode.HYBRID
- Implement custom scoring function

#### Phase 2: Episode Structure
- Create Episode memory type
- Link all memories to episodes during storage
- Add conversation flow metadata
- Implement episode-aware search

#### Phase 3: Query Intelligence
- Add query classifier using simple heuristics
- Implement temporal query handlers
- Add conversation reconstruction logic
- Enable quote extraction

#### Phase 4: Advanced Features
- Implement conversation summary pointers
- Add drill-down capabilities
- Enable time-range queries
- Add speaker-based filtering

## Expected Improvements

1. **Perfect Conversation Recall**: Reconstruct any past conversation exactly
2. **Temporal Awareness**: Handle "What did we discuss yesterday?" queries
3. **Quote Accuracy**: Retrieve exact words said by either party
4. **Context Preservation**: Understand questions in original context
5. **Faster Retrieval**: BM42 keyword matches + semantic search
6. **Relationship Understanding**: Link related memories across time

## Key Innovations

1. **Conversation-First Design**: Treat conversations as first-class objects
2. **Multi-Modal Search**: Combine semantic, keyword, and temporal dimensions
3. **Hierarchical Storage**: Enable both summaries and detailed recall
4. **Dynamic Reranking**: Adjust ranking based on query type and context

## Technical Requirements

### Qdrant Configuration
- Enable hybrid search mode
- Add BM42 sparse embeddings support
- Configure custom reranking functions

### Storage Updates
- Extend memory schema with episode metadata
- Add conversation flow tracking
- Implement bidirectional memory links

### Search Pipeline
- Query intent classifier
- Multi-stage retrieval orchestrator
- Conversation reconstruction engine
- Temporal context analyzer

This upgrade will transform the memory system from simple fact storage to a comprehensive episodic memory system capable of perfect conversation recall with full temporal and contextual awareness.