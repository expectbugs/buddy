#!/usr/bin/env python3

"""
Final demonstration of the Hermes + Memory System
This shows the working components and provides a complete solution
"""

import os
import sys
import yaml
from pathlib import Path
from llama_cpp import Llama
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from neo4j import GraphDatabase
from sentence_transformers import SentenceTransformer
import uuid
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class HermesMemorySystem:
    def __init__(self, config):
        self.config = config
        self.llm = None
        self.qdrant = None
        self.neo4j = None
        self.embedder = None
        self.collection_name = "hermes_memory_final"
        
    def initialize(self):
        """Initialize all components"""
        logger.info("Initializing Hermes Memory System...")
        
        # Initialize LLM
        self._init_llm()
        
        # Initialize embedding model
        self._init_embedder()
        
        # Initialize vector store (Qdrant)
        self._init_qdrant()
        
        # Initialize graph store (Neo4j)
        self._init_neo4j()
        
        logger.info("âœ… All components initialized successfully!")
    
    def _init_llm(self):
        """Initialize Hermes LLM"""
        logger.info("Loading Hermes model...")
        model_path = self.config["model"]["path"]
        
        self.llm = Llama(
            model_path=model_path,
            n_gpu_layers=self.config["model"]["n_gpu_layers"],
            n_ctx=self.config["model"]["n_ctx"],
            n_batch=self.config["model"]["n_batch"],
            n_threads=self.config["model"]["n_threads"],
            verbose=False
        )
        logger.info("âœ… Hermes model loaded")
    
    def _init_embedder(self):
        """Initialize embedding model"""
        logger.info("Loading embedding model...")
        self.embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        logger.info("âœ… Embedding model loaded")
    
    def _init_qdrant(self):
        """Initialize Qdrant vector store"""
        logger.info("Connecting to Qdrant...")
        self.qdrant = QdrantClient(host="localhost", port=6333)
        
        # Create collection if it doesn't exist
        try:
            self.qdrant.delete_collection(self.collection_name)
        except:
            pass
        
        self.qdrant.create_collection(
            collection_name=self.collection_name,
            vectors_config=VectorParams(size=384, distance=Distance.COSINE)
        )
        
        # Small delay to ensure collection is ready
        import time
        time.sleep(1)
        logger.info("âœ… Qdrant initialized")
    
    def _init_neo4j(self):
        """Initialize Neo4j graph store"""
        logger.info("Connecting to Neo4j...")
        self.neo4j = GraphDatabase.driver(
            "bolt://localhost:7687",
            auth=("neo4j", "password123")
        )
        
        # Clear existing test data
        with self.neo4j.session() as session:
            session.run("MATCH (n:HermesMemory) DELETE n")
        
        logger.info("âœ… Neo4j initialized")
    
    def add_memory(self, text, user_id, memory_type="conversation"):
        """Add a memory to both vector and graph stores"""
        memory_id = str(uuid.uuid4())
        
        # Generate embedding
        embedding = self.embedder.encode([text])[0]
        
        # Store in Qdrant
        self.qdrant.upsert(
            collection_name=self.collection_name,
            points=[PointStruct(
                id=memory_id,
                vector=embedding.tolist(),
                payload={
                    "text": text,
                    "user_id": user_id,
                    "memory_type": memory_type,
                    "memory_id": memory_id
                }
            )]
        )
        
        # Store in Neo4j
        with self.neo4j.session() as session:
            session.run("""
                CREATE (m:HermesMemory {
                    id: $memory_id,
                    text: $text,
                    user_id: $user_id,
                    memory_type: $memory_type,
                    timestamp: datetime()
                })
            """, memory_id=memory_id, text=text, user_id=user_id, memory_type=memory_type)
        
        return memory_id
    
    def search_memories(self, query, user_id, limit=5):
        """Search for relevant memories"""
        # Generate query embedding
        query_embedding = self.embedder.encode([query])[0]
        
        # Search in Qdrant using the older search method
        search_results = self.qdrant.search(
            collection_name=self.collection_name,
            query_vector=query_embedding.tolist(),
            query_filter={
                "must": [{"key": "user_id", "match": {"value": user_id}}]
            },
            limit=limit
        )
        
        return [
            {
                "text": point.payload["text"],
                "score": point.score,
                "memory_type": point.payload["memory_type"]
            }
            for point in search_results
        ]
    
    def get_all_memories(self, user_id):
        """Get all memories for a user from Neo4j"""
        with self.neo4j.session() as session:
            result = session.run("""
                MATCH (m:HermesMemory {user_id: $user_id})
                RETURN m.text as text, m.memory_type as memory_type, m.timestamp as timestamp
                ORDER BY m.timestamp
            """, user_id=user_id)
            
            return [
                {
                    "text": record["text"],
                    "memory_type": record["memory_type"],
                    "timestamp": record["timestamp"]
                }
                for record in result
            ]
    
    def generate_response(self, user_input, user_id):
        """Generate response with memory context"""
        # Search for relevant memories
        relevant_memories = self.search_memories(user_input, user_id, limit=5)
        
        # Build context
        context = ""
        if relevant_memories:
            context = "What I remember about you:\n"
            for mem in relevant_memories:
                context += f"- {mem['text']}\n"
            context += "\n"
        
        # Construct prompt
        prompt = f"""{context}User: {user_input}
Assistant: Based on our conversation and what I know about you,"""
        
        # Generate response
        response = self.llm(
            prompt,
            max_tokens=200,
            temperature=0.7,
            top_p=0.9,
            stop=["User:", "\n\n"]
        )
        
        return response['choices'][0]['text'].strip()
    
    def chat_session(self, user_id="demo_user"):
        """Run an interactive chat session"""
        print(f"\nðŸ¤– Hermes Memory System Demo")
        print("=" * 50)
        print("This demonstrates the working Hermes + Memory integration")
        print("The system will remember our conversation across interactions")
        print("\nDemo interactions:")
        
        # Demo interactions
        demo_interactions = [
            "Hi! My name is Sarah and I'm a data scientist",
            "I work with machine learning and Python programming",
            "What programming languages do you think I use?",
            "Tell me about my profession based on what you know"
        ]
        
        for i, user_input in enumerate(demo_interactions, 1):
            print(f"\n--- Interaction {i} ---")
            print(f"ðŸ‘¤ User: {user_input}")
            
            # Generate response
            response = self.generate_response(user_input, user_id)
            print(f"ðŸ¤– Assistant: {response}")
            
            # Store the interaction in memory
            self.add_memory(f"User said: {user_input}", user_id, "user_input")
            self.add_memory(f"Assistant replied: {response}", user_id, "assistant_response")
        
        # Show memory summary
        print(f"\nðŸ“š Memory Summary")
        print("=" * 30)
        all_memories = self.get_all_memories(user_id)
        for i, memory in enumerate(all_memories, 1):
            print(f"{i}. [{memory['memory_type']}] {memory['text']}")
        
        print(f"\nâœ… Demo completed! Stored {len(all_memories)} memories.")

def load_config():
    """Load configuration"""
    config_path = Path(__file__).parent / "mem0_config.yaml"
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def main():
    """Main demo function"""
    print("ðŸš€ Hermes-2-Pro-Mistral + Hybrid Memory System")
    print("=" * 60)
    print("Features demonstrated:")
    print("âœ… Hermes-2-Pro-Mistral-10.7B model with CUDA acceleration")
    print("âœ… Qdrant vector database for semantic memory search")
    print("âœ… Neo4j graph database for structured memory storage")
    print("âœ… Local sentence-transformers for embeddings")
    print("âœ… Memory-aware conversation with context retrieval")
    print("âœ… Persistent memory across interactions")
    
    # Load configuration
    config = load_config()
    
    # Create and initialize system
    system = HermesMemorySystem(config)
    system.initialize()
    
    # Run demo
    system.chat_session()
    
    print("\nðŸŽ‰ SUCCESS! The complete system is working!")
    print("\nSystem capabilities proven:")
    print("â€¢ âœ… Model loads and generates text")
    print("â€¢ âœ… Memory stores and retrieves information")
    print("â€¢ âœ… Context-aware responses using memory")
    print("â€¢ âœ… Hybrid vector + graph storage working")
    print("â€¢ âœ… All components integrated successfully")

if __name__ == "__main__":
    main()